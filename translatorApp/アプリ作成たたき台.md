1. アプリ構成と技術スタックの要約
コストパフォーマンスと医療情報のセキュリティ、および精度のバランスを考慮した構成です。
• アーキテクチャ: マルチテナントSaaS（クリニックごとにデータを論理分離）
• フロントエンド: React (TypeScript) + Vite
    ◦ UI: 医師と患者の会話が左右に分かれるチャット形式。
    ◦ 音声処理: ブラウザでの録音、無音検知（VAD）によるチャンク分割。
• バックエンド: Azure Functions (Python) または Azure App Service
    ◦ 役割: APIのオーケストレーション、使用量ログの保存、認証ガード。
• データベース: Azure SQL Database
    ◦ 重要: TenantID（クリニックID）を用いた行レベルでのデータ分離。BillingLogsテーブルによる従量課金データの蓄積。
• 認証: Microsoft Entra ID (旧 Azure AD) External Identities
    ◦ クリニックごとの組織管理、MFA（多要素認証）対応。
• AI/API構成（ハイブリッド方式）:
    1. 音声認識 & 話者分離: Azure AI Speech Service (Speech to Text)
        ▪ 機能: リアルタイム文字起こし + 言語識別 (Language ID) で話者（日/英）を自動判定。
    2. 翻訳: DeepL API Pro
        ▪ 理由: 医療用語の流暢さとコスト管理のため、Azureの翻訳ではなくDeepLを採用。用語集機能で医療用語を固定。
    3. 要約・カルテ作成: Azure OpenAI Service (GPT-4o)
        ▪ タイミング: 診察終了時のみ実行（コスト抑制）。SOAP形式へ構造化。

--------------------------------------------------------------------------------
2. AIコーディングツール向け開発プロンプト（設計指示書）
以下のテキストをコピーして、AIコーディングツール（CursorのComposer機能やCopilotなど）に入力してください。
# Role
あなたは医療用SaaS開発のエキスパートです。Microsoft Azureのエコシステムと最新のWeb技術を用いて、セキュアで高機能な医療通訳・カルテ作成Webアプリの基盤コードと設計を作成してください。

# Product Goal
外国人患者と日本人医師の会話をリアルタイムで「文字起こし」「翻訳」し、チャット形式で表示する。診察終了後には会話ログからSOAP形式のカルテと英文診断書を自動生成する。
また、クリニックごとのデータ分離と、API使用量に基づく従量課金管理を実装する。

# Tech Stack & Requirements
- **Frontend**: React, TypeScript, Tailwind CSS, shadcn/ui (components).
- **Backend**: Azure Functions (Python v2 model) or FastAPI on Azure App Service.
- **Database**: Azure SQL Database.
- **Authentication**: Microsoft Entra ID (Integrate via MSAL.js).
- **AI Services**:
  - ASR: Azure AI Speech SDK (Speech-to-Text).
  - Translation: DeepL API (Free/Pro tier compatible).
  - Summarization: Azure OpenAI Service (GPT-4o).

# Key Features & Implementation Steps

## 1. Authentication & Multi-tenancy (Security First)
- **Login**: Implement Microsoft Entra ID login.
- **Data Isolation**: All database queries MUST filter by `TenantID` (Clinic ID).
- **Table Schema**:
  - `Tenants` (ID, Name, PlanType)
  - `Users` (ID, TenantID, Email, Role)
  - `Encounters` (ID, TenantID, DoctorID, PatientName, CreatedAt, SOAP_Note, Referral_Letter)
  - `ConversationLogs` (ID, EncounterID, SpeakerRole, OriginalText, TranslatedText, Language, Timestamp)
  - **`BillingLogs`** (ID, TenantID, ServiceType['STT', 'DeepL', 'GPT'], Amount, Timestamp)

## 2. Real-time Speech-to-Text & Translation Flow
This is the core loop. Implement the following logic:
1. **Frontend**:
   - Use browser Microphone API with a VAD (Voice Activity Detection) library (e.g., `hark` or custom logic) to detect speech chunks.
   - Or use Azure Speech SDK's "Continuous Language Identification" to detect if audio is `ja-JP` (Doctor) or `en-US` (Patient).
2. **Backend Processing (Chunk-based)**:
   - Receive audio chunk.
   - Send to **Azure Speech-to-Text**. Get transcription + detected language.
   - **Cost Tracking (1)**: Log audio duration (seconds) to `BillingLogs` (Service='STT').
   - Send text to **DeepL API** for translation.
     - If Source=JA -> Target=EN.
     - If Source=EN -> Target=JA.
   - **Cost Tracking (2)**: Log character count to `BillingLogs` (Service='DeepL').
   - Return `{original, translated, speaker_lang}` to Frontend.
3. **UI Display**:
   - Show a chat interface.
   - Right side (Green bubble): Doctor (Japanese).
   - Left side (White bubble): Patient (Foreign Language).
   - Display both original text and translated text in the bubble.

## 3. Post-Consultation Summarization (The Trigger)
- Create an endpoint `/generate-summary`.
- Input: `EncounterID`.
- Process:
  1. Fetch all `ConversationLogs` for this encounter.
  2. Format conversation history into a structured prompt.
  3. Call **Azure OpenAI (GPT-4o)** with a System Prompt: "You are a medical scribe. Summarize the following conversation into a SOAP note format and generate a referral letter in English."
  4. **Cost Tracking (3)**: Log input/output tokens to `BillingLogs` (Service='GPT').
  5. Save result to `Encounters` table.

## 4. Cost Management System (Background Trigger)
- Design a logic (or Azure Function Timer Trigger) to aggregate `BillingLogs`.
- Logic:
  - Provide an endpoint `/check-usage`.
  - Calculate total cost based on:
    - (STT Seconds * UnitPrice) + (DeepL Chars * UnitPrice) + (GPT Tokens * UnitPrice).
  - If Total > Threshold (e.g., 80% of Plan Limit), trigger an alert (mock function `sendAlertEmail`).

# Constraints & Best Practices
- **Privacy**: Do NOT store audio files permanently; process in memory or ephemeral storage.
- **Error Handling**: DeepL or Azure errors must not crash the chat; allow retry or fallback.
- **Latency**: Ensure the UI updates optimistically or handles asynchronous streams efficiently.
- **Medical Accuracy**: In the DeepL call, assume a `glossary_id` parameter can be passed for future medical term enforcement.

# Deliverables
Please generate the following:
1. **SQL Schema** (`schema.sql`) for the tables described.
2. **Backend API Code** (Python) handling the `/transcribe-and-translate` logic including the billing logging.
3. **Frontend React Component** (`ChatInterface.tsx`) demonstrating the recording and dual-language display logic.
4. **Summarization Prompt Template** for the GPT-4o call.
3. AIへの補足説明（各項目の意図）
このプロンプトをAIに入力すると、具体的なコードが生成されます。それぞれのセクションの意図は以下の通りです。
• Data Isolation (データ分離): ソース情報に基づき、医療データがクリニック間で混ざらないよう、TenantID をすべてのテーブルに入れることを強制しています。
• Cost Tracking (コスト追跡): ユーザー様の「裏でトリガーを取りたい」という要望に基づき、APIを呼ぶたびに即座に軽量なログ(BillingLogs)を保存する設計にしています。これにより、診察のパフォーマンスを落とさずにコスト計算が可能になります。
• Hybrid AI Use: 音声認識にはAzure、翻訳にはDeepL、要約にはGPT-4oと使い分ける指示を出しています。これはソース情報などで示唆された「医師は正確な用語を好む」傾向に対し、DeepLの用語集機能などを将来的に使いやすくするため、およびコスト最適化のためです。
• Language Identification (言語識別): ソース情報にあるような、音声認識APIの言語識別機能を活用し、UI上で医師（右）と患者（左）を自動で振り分けるロジックを組み込んでいます。
まずはこのプロンプトを使って、プロジェクトの雛形（ボイラープレート）を作成させてみてください。